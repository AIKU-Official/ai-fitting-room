# AI Fitting Room

<aside>
ğŸ‘œ í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ì˜·ì„ ì…ì–´ë³¼ ìˆ˜ ìˆë‹¤ë©´?
Virtual Try-On ëª¨ë¸ì„ ì´ìš©í•œ AI í”¼íŒ…ë£¸

</aside>

## ğŸ’ª Our Team

> **ê¹€ì±„í˜„** _Lead_

- Research
- Data Processing
- Experiments
- Presentation

> **ì‹¬í•˜ë¯¼**

- Research
- Data Processing
- Resource
- Training

> **ë…¸ì„±ì£¼**

- Research
- Data Processing
- Presentation

## ğŸ‘— Introduction

### Motivation

ê°€ë”, ë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” ì˜·ë“¤ ì¤‘ ì–´ë–¤ ê±¸ ì½”ë””í•´ì•¼ í• ì§€ ì „í˜€ ê°ì´ ì˜¤ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. â€œì´ë ‡ê²Œ ì…ìœ¼ë©´ ê´œì°®ê² ì§€â€í•˜ê³  ì…ì–´ë´¤ë”ë‹ˆ ë‚´ê°€ ìƒìƒí–ˆë˜ ëª¨ìŠµì´ ì•„ë‹ˆë¼ ë‹¹í™©ìŠ¤ëŸ¬ì› ë˜ ì ë„ ìˆê³ ìš”. ì´ëŸ° ê³ ë¯¼ë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´, ì§ì ‘ ì…ì–´ë³´ì§€ ì•Šê³ ë„ ì˜·ì„ ì…ì€ ë‚˜ì˜ ëª¨ìŠµì„ í™•ì¸í•´ë³¼ ìˆ˜ ìˆë„ë¡ í”¼íŒ…í•´ì£¼ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ë§Œë“¤ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.

![Image from **[TryOnDiffusion: A Tale of Two UNets](https://tryondiffusion.github.io/)**](https://github.com/kchyun/ai-fitting-room/assets/63688973/bd3ab808-3b0f-4456-bc92-6aaea5ee5978)
\*Image from \*\*[TryOnDiffusion: A Tale of Two UNets](https://tryondiffusion.github.io/)\*\*\*

### Goal

ê¸°ì¡´ì˜ ê°€ìƒí”¼íŒ… ëª¨ë¸ë“¤ì€ ëŒ€ê°œ **ìƒì˜ë§Œ ì ìš©ì´ ê°€ëŠ¥**í•˜ë‹¤ëŠ” í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŒ

**â‡’ ì´ë¥¼ í™•ì¥í•´ ìƒì˜, í•˜ì˜ ë° ë“œë ˆìŠ¤ê¹Œì§€ í”¼íŒ… ê°€ëŠ¥í•œ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì!**

## ğŸ“š Dataset

### Dress-Code [[repo]](https://github.com/aimagelab/dress-code)

\*Proposed in â€œ**[Dress Code: High-Resolution Multi-Category Virtual Try-On](https://arxiv.org/abs/2204.08532)â€\***

- 1024 x 768 ê³ í™”ì§ˆ ì´ë¯¸ì§€
- 5ë§Œì—¬ ì¥ì˜ ì˜·, 10ë§Œì—¬ ì¥ì˜ ì „ì‹  ì´ë¯¸ì§€ ë°ì´í„°
- keypoint, skeleton, label map, dense pose ë“± í’ë¶€í•œ annotation ì œê³µ

![Untitled](https://github.com/kchyun/ai-fitting-room/assets/63688973/55be9ea7-22c0-4b96-902b-9677cf535f6f)

## ğŸ“ Modeling

### DAFlow [[repo]](https://github.com/OFA-Sys/DAFlow)

Proposed in **"[Single Stage Virtual Try-on via Deformable Attention Flows](https://arxiv.org/abs/2207.09161)" from ECCV2022**

![Brief description of DAFlow](https://github.com/kchyun/ai-fitting-room/assets/63688973/9aba8dcc-c255-4df0-8fb0-fa9723042253)
_Brief description of DAFlow_

![Input of DAFlow](https://github.com/kchyun/ai-fitting-room/assets/63688973/01cf8d52-bcf9-4ba0-a01f-16acb399b2ee)
_Input of DAFlow_

Deformable attentionì„ ì´ìš©í•œ single stage, end-to-end êµ¬ì¡°ë¡œ, ê¸°ì¡´ multi-stage êµ¬ì¡°ì˜ ë³µì¡ì„±ì„ í•´ê²°í•œ ë‹¨ìˆœí•œ êµ¬ì¡°ì˜ ëª¨ë¸

- **íŠ¹ì§•**
  1. Pyramid feature extraction: coarse-to-fine
  2. Cascade flow estimation: DAFN and DAWarp
  3. Shallow encoder-decoder generation

## â™»ï¸ Data Processing

### What is â€˜Agnosticâ€™?

Target Garmentë¥¼ í•©ì„±í•˜ê³ ì í•˜ëŠ” ìë¦¬ë¥¼ ê²€ì •ìƒ‰ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•œ ì´ë¯¸ì§€. ê¸°ì¡´ ì½”ë“œì—ì„œëŠ” **ìƒì˜ì— ëŒ€í•´ì„œë§Œ keypointì™€ densepose ë°ì´í„°ë¥¼ ì´ìš©**í•´ Agnostic ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” í•˜ì˜ì™€ ë“œë ˆìŠ¤ê¹Œì§€ í•©ì„±í•˜ëŠ” ê²ƒì´ ëª©í‘œì´ë¯€ë¡œ, **í•˜ë°˜ì‹ ê³¼ ì „ì‹  Agnostic ì²˜ë¦¬ê°€ í•„ìš”**í•©ë‹ˆë‹¤.

### Agnostic for full-body

ìƒì²´ëŠ” í‚¤í¬ì¸íŠ¸ì™€ denseposeë§Œì„ ì‚¬ìš©í•´ ì™„ë²½í•˜ê²Œ ë§ˆìŠ¤í‚¹ì´ ê°€ëŠ¥í•˜ì§€ë§Œ, **ê³¨ë°˜ ë¶€ë¶„ì´ ìƒì²´ë¡œ ë¶„ë¥˜ë˜ì–´ ìˆëŠ” Densepose**ì˜ íŠ¹ì„±ìƒ ì£¼ì–´ì§„ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•´ í•˜ì²´ë¥¼ ì™„ë²½í•˜ê²Œ ë§ˆìŠ¤í‚¹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

â‡’ ìƒì˜, ë°”ì§€, ì‹ ë°œ, ëª¨ì ë“± ë‹¤ì–‘í•œ íŒ¨ì…˜ ì•„ì´í…œìœ¼ë¡œ ë ˆì´ë¸”ë§ëœ Dress-Codeì˜ **Label map ë°ì´í„°ë¥¼ ì¶”ê°€ë¡œ ì‚¬ìš©**í•´ í•˜ë°˜ì‹ ì„ ë³´ë‹¤ ì •í™•í•˜ê²Œ ë§ˆìŠ¤í‚¹í–ˆìŠµë‹ˆë‹¤.

- **Upper body**
  - keypoint + densepose
- **Lower body**
  - keypoint + densepose + label map
- **Dresses**
  - Upper + Lower body
    ë™ì‹œì— ì ìš©

![Untitled](https://github.com/kchyun/ai-fitting-room/assets/63688973/beaf385e-e63f-4c7f-acf3-2e3467e1b3cc)

## ğŸ“ Training

### Fine-Tuning

ìŠ¤í¬ë˜ì¹˜ë¶€í„° í•™ìŠµí•œ ê²½ìš° ì´ˆë°˜ Lossê°€ í¬ê³  ìˆ˜ë ´ ì†ë„ê°€ ëŠë ¸ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ìƒë°˜ì‹  ì¤‘ì‹¬ìœ¼ë¡œ í•™ìŠµëœ DAFlowì˜ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì „ì²˜ë¦¬í•œ Dress-Code ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ íŒŒì¸íŠœë‹í–ˆìŠµë‹ˆë‹¤.

### Implementation Detail

- `Epoch`: 10
- `Batch size`: 1
- `Device`: RTX3080 \* 1
- Data Usage
  - Image Resolution: 512 x 384
  - 1800 paired Upper/Lower/Dresses sets each

## ğŸ§ª Results

### Sample results during training

í•™ìŠµ ê³¼ì •ì—ì„œ ì–»ì€ ê²°ê³¼ë¥¼ ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì‹œê°„ìˆœ ë°°ì—´í–ˆìŠµë‹ˆë‹¤. í•™ìŠµí• ìˆ˜ë¡ ë” ì •í™•í•˜ê³ , ìì—°ìŠ¤ëŸ½ê²Œ í•©ì„±í•˜ëŠ” ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. 4ë²ˆì§¸ epoch ì´í›„ë¶€í„°ëŠ” ì˜¤ë²„í”¼íŒ…ì´ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤.

![ìƒì˜ í•©ì„± ê²°ê³¼](https://github.com/kchyun/ai-fitting-room/assets/63688973/64f72b86-3493-4f04-a1b2-a64790eb08f1)
_ìƒì˜ í•©ì„± ê²°ê³¼_

![í•˜ì˜ í•©ì„± ê²°ê³¼](https://github.com/kchyun/ai-fitting-room/assets/63688973/ef36a884-3831-4fb1-9420-ae429173a76b)
_í•˜ì˜ í•©ì„± ê²°ê³¼_

![ë“œë ˆìŠ¤ í•©ì„± ê²°ê³¼](https://github.com/kchyun/ai-fitting-room/assets/63688973/120d30d7-3017-4402-9967-0a722b0ef595)
_ë“œë ˆìŠ¤ í•©ì„± ê²°ê³¼_

### Inference with new images

![Untitled](https://github.com/kchyun/ai-fitting-room/assets/63688973/28c894ff-11b4-49cc-b2cd-af2ba2479f3f)

## â›” Limitation

![Failure cases.

1. ë³µì¡í•œ íŒ” í˜•íƒœì— ë§ê²Œ í•©ì„±ì— ì‹¤íŒ¨í•œ ê²½ìš°
   2~3. ë“œë ˆìŠ¤ì˜ ë„¥ë¼ì¸ ë””í…Œì¼ì´ ì‚¬ë¼ì§€ëŠ” ê²½ìš°](https://github.com/kchyun/ai-fitting-room/assets/63688973/c729ddad-5fde-4c43-96fe-a5f461c45f2f)
   _Failure cases: 1. ë³µì¡í•œ íŒ” í˜•íƒœì— ë§ê²Œ í•©ì„±ì— ì‹¤íŒ¨í•œ ê²½ìš°, 2~3. ë“œë ˆìŠ¤ì˜ ë„¥ë¼ì¸ ë””í…Œì¼ì´ ì‚¬ë¼ì§€ëŠ” ê²½ìš°_

- Agnostic maskì˜ í˜•íƒœì— ë¯¼ê°
- ë³µì¡í•œ í¬ì¦ˆì— ëŒ€í•œ ì ì‘ë ¥ ë–¨ì–´ì§
- ì˜·ì˜ ë””í…Œì¼ì´ ë³€í˜•ë˜ëŠ” ê²½ìš° ì¡´ì¬

# ğŸ¤” Future Works

### Performance

- ì¼ë°˜ì ì´ê³  íš¨ê³¼ì ì¸ Agnostic mask í˜•íƒœ ì—°êµ¬
- ì˜·ì˜ ë””í…Œì¼ì„ ë³´ì¡´í•˜ë©° í•©ì„±í•˜ë„ë¡ ê°œì„ 
- ë‹¤ì–‘í•œ ë°°ê²½ê³¼ ê°ë„ì˜ ì´ë¯¸ì§€ì— ê°•ê±´í•˜ë„ë¡ í•™ìŠµ

### Application

- ë‹¤ë¥¸ VITON ì‘ìš© ë¶„ì•¼ì™€ì˜ ê²°í•©
- ë°ëª¨ í˜ì´ì§€ ë° ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°
